"""
Korean ASR RTX 4060 - Basic Usage Examples
í•œêµ­ì–´ ìŒì„± ì¸ì‹ ê¸°ë³¸ ì‚¬ìš©ë²• ì˜ˆì œ
"""

import sys
import os
from pathlib import Path
import numpy as np
import soundfile as sf
import time
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_environment():
    """í™˜ê²½ ì„¤ì • í™•ì¸"""
    print("ğŸ” í™˜ê²½ í™•ì¸ ì¤‘...")

    try:
        import torch
        print(f"âœ… PyTorch {torch.__version__}")

        if torch.cuda.is_available():
            print(f"âœ… CUDA {torch.version.cuda}")
            print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
            memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"âœ… VRAM: {memory_gb:.1f} GB")
        else:
            print("âš ï¸  CUDA ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰")

    except ImportError as e:
        print(f"âŒ PyTorch ì„¤ì¹˜ í™•ì¸ í•„ìš”: {e}")
        return False

    try:
        import transformers
        print(f"âœ… Transformers {transformers.__version__}")
    except ImportError as e:
        print(f"âŒ Transformers ì„¤ì¹˜ í™•ì¸ í•„ìš”: {e}")
        return False

    try:
        import librosa
        print(f"âœ… Librosa {librosa.__version__}")
    except ImportError as e:
        print(f"âŒ Librosa ì„¤ì¹˜ í™•ì¸ í•„ìš”: {e}")
        return False

    return True

def create_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    directories = [
        "config",
        "data/sample_audio",
        "data/outputs",
        "data/temp",
        "logs"
    ]

    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)

    print("ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ")

def create_config_file():
    """ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
    config_content = """# Korean ASR RTX4060 Configuration
model:
  name: "kresnik/wav2vec2-large-xlsr-korean"
  torch_dtype: "float16"
  device: "cuda"
  low_cpu_mem_usage: true

audio:
  sample_rate: 16000
  max_chunk_length: 30
  min_chunk_length: 1
  overlap: 0.1

memory:
  clear_cache_after_chunk: true
  monitor_memory: true
  max_vram_usage: 7.5

performance:
  batch_size: 1
  num_workers: 1
  pin_memory: true

output:
  save_results: true
  output_dir: "data/outputs"
  timestamp_format: "%Y%m%d_%H%M%S"

logging:
  level: "INFO"
  file: "logs/asr.log"
  console: true

paths:
  data_dir: "data"
  sample_audio_dir: "data/sample_audio"
  outputs_dir: "data/outputs"
  temp_dir: "data/temp"
"""

    config_path = Path("config/config.yaml")
    if not config_path.exists():
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(config_content)
        print("âš™ï¸  ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ")

def create_sample_audio():
    """ìƒ˜í”Œ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±"""
    print("ğŸµ ìƒ˜í”Œ ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")

    sample_dir = Path("data/sample_audio")
    sr = 16000

    # ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„±
    samples = [
        ("test_short.wav", 5, 440),      # 5ì´ˆ, 440Hz
        ("test_medium.wav", 15, 880),    # 15ì´ˆ, 880Hz
        ("test_long.wav", 45, 220),      # 45ì´ˆ, 220Hz
    ]

    for filename, duration, freq in samples:
        t = np.linspace(0, duration, duration * sr, False)
        # ê¸°ë³¸ ì‚¬ì¸íŒŒ + ì•½ê°„ì˜ ë³€ì¡°
        audio = 0.1 * np.sin(2 * np.pi * freq * t) * (1 + 0.1 * np.sin(2 * np.pi * 2 * t))

        output_path = sample_dir / filename
        sf.write(str(output_path), audio, sr)
        print(f"  âœ… {filename} ({duration}ì´ˆ)")

    print("ğŸµ ìƒ˜í”Œ ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ")

def example_1_simple_transcription():
    """ì˜ˆì œ 1: ê°„ë‹¨í•œ ìŒì„± ì¸ì‹"""
    print("\n" + "="*60)
    print("ì˜ˆì œ 1: ê°„ë‹¨í•œ ìŒì„± ì¸ì‹")
    print("="*60)

    try:
        # ëª¨ë“ˆ ì„í¬íŠ¸
        from src.core.memory_manager import MemoryManager
        from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
        import torch

        # ì„¤ì •
        model_name = "kresnik/wav2vec2-large-xlsr-korean"
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        print(f"ğŸ¤– ëª¨ë¸: {model_name}")
        print(f"ğŸ”§ ì¥ì¹˜: {device}")

        # ë©”ëª¨ë¦¬ ê´€ë¦¬ì
        memory_manager = MemoryManager()

        with memory_manager:
            # ëª¨ë¸ ë¡œë“œ
            print("ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘...")
            processor = Wav2Vec2Processor.from_pretrained(model_name)
            model = Wav2Vec2ForCTC.from_pretrained(
                model_name,
                torch_dtype=torch.float16,
                low_cpu_mem_usage=True
            ).to(device)
            model.eval()

            memory_manager.monitor_memory("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

            # í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ë¡œë“œ
            audio_file = "data/sample_audio/test_short.wav"
            if Path(audio_file).exists():
                import librosa
                audio, sr = librosa.load(audio_file, sr=16000, mono=True)

                print(f"ğŸµ ì˜¤ë””ì˜¤: {len(audio)/sr:.1f}ì´ˆ")

                # ì „ì‚¬ ìˆ˜í–‰
                start_time = time.time()

                inputs = processor(audio, sampling_rate=16000, return_tensors="pt", padding=True)
                input_values = inputs.input_values.to(device, dtype=torch.float16)

                with torch.no_grad():
                    logits = model(input_values).logits

                predicted_ids = torch.argmax(logits, dim=-1)
                transcription = processor.batch_decode(predicted_ids)[0]

                processing_time = time.time() - start_time
                rtf = processing_time / (len(audio) / sr)

                print(f"ğŸ“ ê²°ê³¼: {transcription}")
                print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
                print(f"ğŸš€ RTF: {rtf:.3f}x")

                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del inputs, input_values, logits, predicted_ids
                memory_manager.clear_cache()

            else:
                print(f"âš ï¸  ìƒ˜í”Œ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {audio_file}")

        print("âœ… ì˜ˆì œ 1 ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ ì˜ˆì œ 1 ì‹¤íŒ¨: {e}")
        logger.error(f"Example 1 failed: {e}", exc_info=True)

def example_2_chunk_processing():
    """ì˜ˆì œ 2: ì²­í¬ ì²˜ë¦¬"""
    print("\n" + "="*60)
    print("ì˜ˆì œ 2: ê¸´ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬")
    print("="*60)

    try:
        from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
        import torch
        import librosa

        # ì„¤ì •
        model_name = "kresnik/wav2vec2-large-xlsr-korean"
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        chunk_length = 30  # 30ì´ˆ ì²­í¬

        # ëª¨ë¸ ë¡œë“œ
        print("ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘...")
        processor = Wav2Vec2Processor.from_pretrained(model_name)
        model = Wav2Vec2ForCTC.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            low_cpu_mem_usage=True
        ).to(device)
        model.eval()

        # ê¸´ ì˜¤ë””ì˜¤ ë¡œë“œ
        audio_file = "data/sample_audio/test_long.wav"
        if Path(audio_file).exists():
            audio, sr = librosa.load(audio_file, sr=16000, mono=True)
            duration = len(audio) / sr

            print(f"ğŸµ ì „ì²´ ì˜¤ë””ì˜¤: {duration:.1f}ì´ˆ")

            # ì²­í¬ë¡œ ë¶„í• 
            chunk_samples = chunk_length * sr
            chunks = []

            for i in range(0, len(audio), chunk_samples):
                chunk = audio[i:i + chunk_samples]
                if len(chunk) > sr:  # 1ì´ˆ ì´ìƒì¸ ì²­í¬ë§Œ
                    chunks.append({
                        'audio': chunk,
                        'start_time': i / sr,
                        'end_time': min((i + len(chunk)) / sr, duration)
                    })

            print(f"ğŸ“¦ ì²­í¬ ìˆ˜: {len(chunks)}")

            # ì²­í¬ë³„ ì²˜ë¦¬
            results = []
            total_processing_time = 0

            for i, chunk_data in enumerate(chunks):
                print(f"ğŸ”„ ì²­í¬ {i+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘...")

                chunk_audio = chunk_data['audio']
                start_time = time.time()

                # ì „ì‚¬
                inputs = processor(chunk_audio, sampling_rate=16000, return_tensors="pt", padding=True)
                input_values = inputs.input_values.to(device, dtype=torch.float16)

                with torch.no_grad():
                    logits = model(input_values).logits

                predicted_ids = torch.argmax(logits, dim=-1)
                transcription = processor.batch_decode(predicted_ids)[0]

                processing_time = time.time() - start_time
                total_processing_time += processing_time

                chunk_result = {
                    'index': i,
                    'start_time': chunk_data['start_time'],
                    'end_time': chunk_data['end_time'],
                    'text': transcription,
                    'processing_time': processing_time
                }

                results.append(chunk_result)

                print(f"  ğŸ“ ê²°ê³¼: {transcription[:50]}...")
                print(f"  â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")

                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del inputs, input_values, logits, predicted_ids
                torch.cuda.empty_cache() if torch.cuda.is_available() else None

            # ì „ì²´ ê²°ê³¼
            full_text = " ".join([r['text'] for r in results])
            overall_rtf = total_processing_time / duration

            print(f"\nğŸ“„ ì „ì²´ í…ìŠ¤íŠ¸: {full_text}")
            print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {total_processing_time:.2f}ì´ˆ")
            print(f"ğŸš€ ì „ì²´ RTF: {overall_rtf:.3f}x")

        else:
            print(f"âš ï¸  ìƒ˜í”Œ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {audio_file}")

        print("âœ… ì˜ˆì œ 2 ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ ì˜ˆì œ 2 ì‹¤íŒ¨: {e}")
        logger.error(f"Example 2 failed: {e}", exc_info=True)

def example_3_memory_monitoring():
    """ì˜ˆì œ 3: ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§"""
    print("\n" + "="*60)
    print("ì˜ˆì œ 3: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§")
    print("="*60)

    try:
        import torch
        import psutil

        def get_memory_info():
            info = {
                "cpu_percent": psutil.virtual_memory().percent,
                "cpu_available_gb": psutil.virtual_memory().available / (1024**3)
            }

            if torch.cuda.is_available():
                info.update({
                    "gpu_allocated_gb": torch.cuda.memory_allocated() / (1024**3),
                    "gpu_reserved_gb": torch.cuda.memory_reserved() / (1024**3),
                    "gpu_total_gb": torch.cuda.get_device_properties(0).total_memory / (1024**3)
                })

            return info

        def print_memory_info(stage):
            info = get_memory_info()
            print(f"ğŸ’¾ {stage}:")
            print(f"  CPU: {info['cpu_percent']:.1f}% ì‚¬ìš©, {info['cpu_available_gb']:.1f}GB ì‚¬ìš©ê°€ëŠ¥")

            if torch.cuda.is_available():
                print(f"  GPU: {info['gpu_allocated_gb']:.2f}GB í• ë‹¹, "
                      f"{info['gpu_reserved_gb']:.2f}GB ì˜ˆì•½, "
                      f"{info['gpu_total_gb']:.1f}GB ì´ìš©ëŸ‰")

        # ì´ˆê¸° ìƒíƒœ
        print_memory_info("ì´ˆê¸° ìƒíƒœ")

        # ëª¨ë¸ ë¡œë“œ
        from transformers import Wav2Vec2Processor
        print("\nğŸ“¥ í”„ë¡œì„¸ì„œ ë¡œë”©...")
        processor = Wav2Vec2Processor.from_pretrained("kresnik/wav2vec2-large-xlsr-korean")
        print_memory_info("í”„ë¡œì„¸ì„œ ë¡œë“œ í›„")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del processor
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        print_memory_info("ì •ë¦¬ í›„")

        print("âœ… ì˜ˆì œ 3 ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ ì˜ˆì œ 3 ì‹¤íŒ¨: {e}")
        logger.error(f"Example 3 failed: {e}", exc_info=True)

def example_4_performance_test():
    """ì˜ˆì œ 4: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("ì˜ˆì œ 4: ë‹¤ì–‘í•œ ê¸¸ì´ ì˜¤ë””ì˜¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("="*60)

    try:
        from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
        import torch

        # ì„¤ì •
        model_name = "kresnik/wav2vec2-large-xlsr-korean"
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # ëª¨ë¸ ë¡œë“œ
        print("ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘...")
        processor = Wav2Vec2Processor.from_pretrained(model_name)
        model = Wav2Vec2ForCTC.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            low_cpu_mem_usage=True
        ).to(device)
        model.eval()

        # ë‹¤ì–‘í•œ ê¸¸ì´ì˜ í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤
        test_durations = [5, 10, 20, 30]  # ì´ˆ
        sr = 16000

        results = []

        print(f"ğŸƒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì¥ì¹˜: {device})")
        print(f"{'ê¸¸ì´':<8} {'ì²˜ë¦¬ì‹œê°„':<10} {'RTF':<8} {'ìƒíƒœ':<10}")
        print("-" * 40)

        for duration in test_durations:
            # í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„±
            t = np.linspace(0, duration, duration * sr, False)
            test_audio = 0.1 * np.sin(2 * np.pi * 440 * t)

            # ì„±ëŠ¥ ì¸¡ì •
            start_time = time.time()

            try:
                inputs = processor(test_audio, sampling_rate=16000, return_tensors="pt", padding=True)
                input_values = inputs.input_values.to(device, dtype=torch.float16)

                with torch.no_grad():
                    logits = model(input_values).logits

                predicted_ids = torch.argmax(logits, dim=-1)
                transcription = processor.batch_decode(predicted_ids)[0]

                processing_time = time.time() - start_time
                rtf = processing_time / duration
                status = "ì‹¤ì‹œê°„" if rtf < 1.0 else "ëŠë¦¼"

                results.append({
                    'duration': duration,
                    'processing_time': processing_time,
                    'rtf': rtf,
                    'status': status
                })

                print(f"{duration:<8} {processing_time:<10.2f} {rtf:<8.3f} {status:<10}")

                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del inputs, input_values, logits, predicted_ids
                torch.cuda.empty_cache() if torch.cuda.is_available() else None

            except Exception as e:
                print(f"{duration:<8} {'ì‹¤íŒ¨':<10} {'-':<8} {str(e)[:10]:<10}")

        # ê²°ê³¼ ìš”ì•½
        if results:
            avg_rtf = sum(r['rtf'] for r in results) / len(results)
            print(f"\nğŸ“Š í‰ê·  RTF: {avg_rtf:.3f}x")

            if avg_rtf < 1.0:
                print("âœ… ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥!")
            else:
                print("âš ï¸  ì‹¤ì‹œê°„ë³´ë‹¤ ëŠë¦¼ - ì²­í¬ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”")

        print("âœ… ì˜ˆì œ 4 ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ ì˜ˆì œ 4 ì‹¤íŒ¨: {e}")
        logger.error(f"Example 4 failed: {e}", exc_info=True)

def example_5_save_results():
    """ì˜ˆì œ 5: ê²°ê³¼ ì €ì¥"""
    print("\n" + "="*60)
    print("ì˜ˆì œ 5: ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥")
    print("="*60)

    try:
        # ìƒ˜í”Œ ê²°ê³¼ ë°ì´í„°
        sample_result = {
            "text": "ì•ˆë…•í•˜ì„¸ìš”. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ìŒì„± ì¸ì‹ ê²°ê³¼ì…ë‹ˆë‹¤.",
            "chunks": [
                {
                    "index": 0,
                    "start_time": 0.0,
                    "end_time": 3.5,
                    "text": "ì•ˆë…•í•˜ì„¸ìš”.",
                    "duration": 3.5
                },
                {
                    "index": 1,
                    "start_time": 3.5,
                    "end_time": 8.2,
                    "text": "ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ìŒì„± ì¸ì‹ ê²°ê³¼ì…ë‹ˆë‹¤.",
                    "duration": 4.7
                }
            ],
            "stats": {
                "total_processing_time": 1.2,
                "real_time_factor": 0.15,
                "chunks_processed": 2
            }
        }

        output_dir = Path("data/outputs")
        timestamp = time.strftime("%Y%m%d_%H%M%S")

        # 1. JSON ì €ì¥
        json_file = output_dir / f"result_{timestamp}.json"
        import json
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(sample_result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ JSON ì €ì¥: {json_file}")

        # 2. í…ìŠ¤íŠ¸ ì €ì¥
        txt_file = output_dir / f"result_{timestamp}.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(sample_result['text'])
        print(f"ğŸ’¾ í…ìŠ¤íŠ¸ ì €ì¥: {txt_file}")

        # 3. SRT ìë§‰ ì €ì¥
        srt_file = output_dir / f"result_{timestamp}.srt"
        with open(srt_file, 'w', encoding='utf-8') as f:
            for i, chunk in enumerate(sample_result['chunks']):
                # SRT ì‹œê°„ í¬ë§·
                def format_srt_time(seconds):
                    hours = int(seconds // 3600)
                    minutes = int((seconds % 3600) // 60)
                    secs = int(seconds % 60)
                    ms = int((seconds % 1) * 1000)
                    return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"

                f.write(f"{i + 1}\n")
                f.write(f"{format_srt_time(chunk['start_time'])} --> {format_srt_time(chunk['end_time'])}\n")
                f.write(f"{chunk['text']}\n\n")
        print(f"ğŸ’¾ SRT ìë§‰ ì €ì¥: {srt_file}")

        # 4. CSV ì €ì¥
        csv_file = output_dir / f"result_{timestamp}.csv"
        import csv
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['Index', 'Start_Time', 'End_Time', 'Duration', 'Text'])
            for chunk in sample_result['chunks']:
                writer.writerow([
                    chunk['index'],
                    chunk['start_time'],
                    chunk['end_time'],
                    chunk['duration'],
                    chunk['text']
                ])
        print(f"ğŸ’¾ CSV ì €ì¥: {csv_file}")

        print("âœ… ì˜ˆì œ 5 ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ ì˜ˆì œ 5 ì‹¤íŒ¨: {e}")
        logger.error(f"Example 5 failed: {e}", exc_info=True)

def show_usage_tips():
    """ì‚¬ìš© íŒ ì¶œë ¥"""
    print("\n" + "="*60)
    print("ğŸ’¡ ì‚¬ìš© íŒ")
    print("="*60)

    tips = [
        "ğŸµ ì‹¤ì œ í•œêµ­ì–´ ìŒì„± íŒŒì¼ì„ data/sample_audio/ì— ë³µì‚¬í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”",
        "ğŸ”§ RTX 4060ì—ì„œëŠ” 30ì´ˆ ì²­í¬ í¬ê¸°ê°€ ìµœì ì…ë‹ˆë‹¤",
        "ğŸ’¾ ê²°ê³¼ëŠ” data/outputs/ ë””ë ‰í† ë¦¬ì— ìë™ ì €ì¥ë©ë‹ˆë‹¤",
        "ğŸ“Š RTF < 1.0ì´ë©´ ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤",
        "ğŸ¤ ì‹¤ì‹œê°„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ PyAudioë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”",
        "ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ëŠ” python -m src.apps.batch_appì„ ì‚¬ìš©í•˜ì„¸ìš”",
        "âš™ï¸  config/config.yamlì—ì„œ ì„¤ì •ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
        "ğŸš€ ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì²­í¬ í¬ê¸°ë¥¼ 20ì´ˆë¡œ ì¤„ì—¬ë³´ì„¸ìš”",
    ]

    for tip in tips:
        print(f"  {tip}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ‡°ğŸ‡· Korean ASR RTX 4060 - Basic Usage Examples")
    print("í•œêµ­ì–´ ìŒì„± ì¸ì‹ ê¸°ë³¸ ì‚¬ìš©ë²• ì˜ˆì œ")
    print("=" * 80)

    # í™˜ê²½ í™•ì¸
    if not check_environment():
        print("âŒ í™˜ê²½ ì„¤ì •ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ìƒì„±
    create_directories()
    create_config_file()
    create_sample_audio()

    print("\nğŸš€ ì˜ˆì œ ì‹œì‘!")

    try:
        # ì˜ˆì œë“¤ ì‹¤í–‰
        example_1_simple_transcription()
        example_2_chunk_processing()
        example_3_memory_monitoring()
        example_4_performance_test()
        example_5_save_results()

        # ì‚¬ìš© íŒ
        show_usage_tips()

        print("\n" + "="*80)
        print("ğŸ‰ ëª¨ë“  ì˜ˆì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤ì€ data/outputs/ ë””ë ‰í† ë¦¬ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("ğŸ“š ë” ìì„¸í•œ ì‚¬ìš©ë²•ì€ README.mdë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.")

    except KeyboardInterrupt:
        print("\nâ¹ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error(f"Unexpected error: {e}", exc_info=True)

        print("\nğŸ”§ ë¬¸ì œ í•´ê²°:")
        print("1. ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("2. ëª¨ë“  íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("3. CUDA ë“œë¼ì´ë²„ê°€ ì •ìƒì¸ì§€ í™•ì¸")

if __name__ == "__main__":
    main()